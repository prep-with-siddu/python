# 5.2 File Handling â€” Notes

> **Status**: âœ… Completed  
> **Date**: 28 February 2026

---

## 1. Reading Files (`open`, `read`, `readline`, `readlines`)

```python
# ---- open() and read() â€” entire file at once ----
with open("sample.txt", "r") as f:
    content = f.read()            # Entire file as one string
    print(content)

# ---- read(n) â€” read n characters ----
with open("sample.txt", "r") as f:
    chunk = f.read(10)            # First 10 characters
    print(chunk)

# ---- readline() â€” one line at a time ----
with open("sample.txt", "r") as f:
    line1 = f.readline()          # First line (includes \n)
    line2 = f.readline()          # Second line
    print(line1.strip())          # .strip() removes \n

# ---- readlines() â€” all lines as a list ----
with open("sample.txt", "r") as f:
    lines = f.readlines()         # ['line1\n', 'line2\n', 'line3\n']
    print(lines)

# ---- Iterating line by line (BEST for large files â€” memory efficient!) ----
with open("sample.txt", "r") as f:
    for line in f:                # f is an iterator â€” reads one line at a time
        print(line.strip())

# ---- Read into a clean list (no \n) ----
with open("sample.txt", "r") as f:
    lines = [line.strip() for line in f]
    print(lines)    # ['line1', 'line2', 'line3']
```

### Encoding
```python
# UTF-8 is the default, but always be explicit for safety
with open("sample.txt", "r", encoding="utf-8") as f:
    content = f.read()

# For files with different encodings
with open("legacy.txt", "r", encoding="latin-1") as f:
    content = f.read()
```

> ğŸ’¡ **Backend rule**: For large files, NEVER use `read()` or `readlines()` â€” they load everything into memory. Iterate line by line.

---

## 2. Writing Files (`write`, `writelines`)

```python
# ---- write() â€” writes a string ----
with open("output.txt", "w") as f:    # "w" = write mode (OVERWRITES!)
    f.write("Hello, World!\n")
    f.write("Second line\n")

# ---- writelines() â€” writes a list of strings (NO auto-newline!) ----
lines = ["Line 1\n", "Line 2\n", "Line 3\n"]
with open("output.txt", "w") as f:
    f.writelines(lines)

# ---- Append mode â€” adds to end, doesn't overwrite ----
with open("output.txt", "a") as f:
    f.write("Appended line\n")

# ---- print() to file ----
with open("output.txt", "w") as f:
    print("Hello", "World", sep=", ", file=f)    # Hello, World
    print("Line 2", file=f)

# ---- Write with newlines from a list ----
data = ["apple", "banana", "cherry"]
with open("fruits.txt", "w") as f:
    f.write("\n".join(data))    # apple\nbanana\ncherry
```

### Write Numbers (Must Convert to String)
```python
numbers = [1, 2, 3, 4, 5]

with open("numbers.txt", "w") as f:
    for n in numbers:
        f.write(f"{n}\n")          # Must be string!
    # Or:
    # f.writelines(f"{n}\n" for n in numbers)
```

---

## 3. File Modes

| Mode | Description | Existing File | File Missing |
|------|------------|---------------|-------------|
| `"r"` | Read (default) | Reads from start | `FileNotFoundError` |
| `"w"` | Write | **Overwrites!** | Creates new |
| `"a"` | Append | Adds at end | Creates new |
| `"x"` | Exclusive create | `FileExistsError` | Creates new |
| `"r+"` | Read + Write | Read/write from start | `FileNotFoundError` |
| `"w+"` | Write + Read | **Overwrites!** Read/write | Creates new |
| `"a+"` | Append + Read | Append + read | Creates new |
| `"rb"` | Read binary | Binary data | `FileNotFoundError` |
| `"wb"` | Write binary | **Overwrites!** Binary | Creates new |

```python
# Binary mode â€” for images, PDFs, etc.
with open("image.png", "rb") as f:
    data = f.read()    # bytes object
    print(type(data))  # <class 'bytes'>

with open("copy.png", "wb") as f:
    f.write(data)

# Read + Write mode
with open("data.txt", "r+") as f:
    content = f.read()
    f.seek(0)                  # Go back to start
    f.write("NEW HEADER\n")   # Overwrites from position 0

# Exclusive create â€” safe for creating new files
try:
    with open("new_config.txt", "x") as f:
        f.write("fresh config")
except FileExistsError:
    print("File already exists!")
```

### `seek()` and `tell()`
```python
with open("sample.txt", "r") as f:
    print(f.tell())       # 0 (current position)
    f.read(5)             # Read 5 characters
    print(f.tell())       # 5
    f.seek(0)             # Go back to start
    print(f.tell())       # 0
```

---

## 4. `with` Statement for File Handling

```python
# âŒ Without `with` â€” risky! File might not close on error
f = open("data.txt", "r")
try:
    content = f.read()
    # If error occurs here, f.close() never runs!
finally:
    f.close()

# âœ… With `with` â€” automatic close, guaranteed!
with open("data.txt", "r") as f:
    content = f.read()
# f is automatically closed here â€” even if exception occurred!

# Check if file is closed
with open("data.txt") as f:
    pass
print(f.closed)    # True (auto-closed!)

# Multiple files
with open("input.txt") as infile, open("output.txt", "w") as outfile:
    for line in infile:
        outfile.write(line.upper())
```

> ğŸ’¡ **Rule**: ALWAYS use `with` for file operations. No exceptions (pun intended).

---

## 5. Working with CSV Files (`csv` Module)

```python
import csv

# ---- Writing CSV ----
data = [
    ["Name", "Age", "City"],
    ["Sid", 25, "Bangalore"],
    ["Rahul", 30, "Mumbai"],
    ["Priya", 28, "Delhi"],
]

with open("users.csv", "w", newline="") as f:    # newline="" prevents extra blank lines
    writer = csv.writer(f)
    writer.writerows(data)        # Write all rows at once
    # Or one by one:
    # writer.writerow(["Name", "Age"])  

# ---- Reading CSV ----
with open("users.csv", "r") as f:
    reader = csv.reader(f)
    header = next(reader)         # Skip header row
    for row in reader:
        print(f"{row[0]} is {row[1]} from {row[2]}")
# Sid is 25 from Bangalore
# Rahul is 30 from Mumbai

# ---- DictReader / DictWriter (use column names!) ----
# Writing
users = [
    {"name": "Sid", "age": 25, "city": "Bangalore"},
    {"name": "Rahul", "age": 30, "city": "Mumbai"},
]

with open("users.csv", "w", newline="") as f:
    writer = csv.DictWriter(f, fieldnames=["name", "age", "city"])
    writer.writeheader()          # Writes header row
    writer.writerows(users)       # Writes all dicts

# Reading
with open("users.csv", "r") as f:
    reader = csv.DictReader(f)
    for row in reader:
        print(row)
# {'name': 'Sid', 'age': '25', 'city': 'Bangalore'}
# {'name': 'Rahul', 'age': '30', 'city': 'Mumbai'}
```

### CSV with Different Delimiters
```python
# Tab-separated (TSV)
with open("data.tsv", "w", newline="") as f:
    writer = csv.writer(f, delimiter="\t")
    writer.writerow(["Name", "Score"])
    writer.writerow(["Sid", 95])

# Pipe-separated
with open("data.psv", "r") as f:
    reader = csv.reader(f, delimiter="|")
```

> ğŸ’¡ **Backend tip**: For large CSV processing, use `pandas`. For simple I/O, `csv` module is fine.

---

## 6. Working with JSON Files (`json` Module)

```python
import json

# ---- Python â†” JSON type mapping ----
# dict   â†” object {}
# list   â†” array []
# str    â†” string ""
# int    â†” number
# float  â†” number
# True   â†” true
# False  â†” false
# None   â†” null

data = {
    "name": "Sid",
    "age": 25,
    "skills": ["Python", "Django", "FastAPI"],
    "active": True,
    "address": None
}

# ---- dumps() â€” Python dict â†’ JSON string ----
json_string = json.dumps(data)
print(json_string)
# {"name": "Sid", "age": 25, "skills": ["Python", "Django", "FastAPI"], "active": true, "address": null}

# Pretty print
json_pretty = json.dumps(data, indent=2, sort_keys=True)
print(json_pretty)

# ---- loads() â€” JSON string â†’ Python dict ----
parsed = json.loads(json_string)
print(parsed["name"])    # Sid
print(type(parsed))      # <class 'dict'>

# ---- dump() â€” Write to file ----
with open("user.json", "w") as f:
    json.dump(data, f, indent=2)

# ---- load() â€” Read from file ----
with open("user.json", "r") as f:
    loaded = json.load(f)
    print(loaded["skills"])    # ['Python', 'Django', 'FastAPI']
```

### Handling Non-Serializable Types
```python
import json
from datetime import datetime, date

data = {
    "name": "Sid",
    "created_at": datetime.now(),    # Not JSON serializable!
    "birthday": date(2001, 5, 15),
}

# âŒ json.dumps(data)  â†’ TypeError: Object of type datetime is not JSON serializable

# âœ… Custom encoder
class DateTimeEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        return super().default(obj)

json_str = json.dumps(data, cls=DateTimeEncoder, indent=2)
print(json_str)
# {
#   "name": "Sid",
#   "created_at": "2026-02-28T10:30:00",
#   "birthday": "2001-05-15"
# }

# âœ… Or use default= parameter (simpler)
json_str = json.dumps(data, default=str, indent=2)    # Converts anything to string
```

### Memory Trick
```
dumps = dump STRING  (returns string)
loads = load STRING  (parses string)
dump  = dump to FILE (writes to file)
load  = load from FILE (reads from file)
```

> ğŸ’¡ **Backend essential**: JSON is the language of APIs. You'll use `json` module daily.

---

## 7. Working with YAML Files (`pyyaml`)

```python
# pip install pyyaml
import yaml

# ---- Write YAML ----
config = {
    "database": {
        "host": "localhost",
        "port": 5432,
        "name": "mydb",
    },
    "debug": True,
    "allowed_hosts": ["localhost", "127.0.0.1"],
}

with open("config.yaml", "w") as f:
    yaml.dump(config, f, default_flow_style=False)

# config.yaml:
# database:
#   host: localhost
#   name: mydb
#   port: 5432
# debug: true
# allowed_hosts:
# - localhost
# - 127.0.0.1

# ---- Read YAML ----
with open("config.yaml", "r") as f:
    loaded = yaml.safe_load(f)    # âœ… Always use safe_load (not yaml.load!)
    print(loaded["database"]["host"])    # localhost

# âš ï¸ NEVER use yaml.load() without Loader â€” security risk!
# yaml.load(f)                  # âŒ Dangerous â€” can execute arbitrary code
# yaml.safe_load(f)             # âœ… Safe
# yaml.load(f, Loader=yaml.SafeLoader)  # âœ… Also safe
```

> ğŸ’¡ Use YAML for config files (Docker Compose, Kubernetes, CI/CD). Use JSON for APIs.

---

## 8. Working with XML (`xml.etree.ElementTree`)

```python
import xml.etree.ElementTree as ET

# ---- Parse XML string ----
xml_string = """
<users>
    <user id="1">
        <name>Sid</name>
        <age>25</age>
    </user>
    <user id="2">
        <name>Rahul</name>
        <age>30</age>
    </user>
</users>
"""

root = ET.fromstring(xml_string)

for user in root.findall("user"):
    user_id = user.get("id")              # Attribute
    name = user.find("name").text         # Child element text
    age = user.find("age").text
    print(f"User {user_id}: {name}, age {age}")
# User 1: Sid, age 25
# User 2: Rahul, age 30

# ---- Parse from file ----
# tree = ET.parse("data.xml")
# root = tree.getroot()

# ---- Create XML ----
root = ET.Element("config")
db = ET.SubElement(root, "database")
ET.SubElement(db, "host").text = "localhost"
ET.SubElement(db, "port").text = "5432"

tree = ET.ElementTree(root)
tree.write("config.xml", encoding="unicode", xml_declaration=True)
```

> ğŸ’¡ XML is less common in modern APIs (JSON won), but you'll encounter it in SOAP APIs, RSS feeds, and legacy systems.

---

## 9. Working with `.env` Files (`python-dotenv`)

```python
# pip install python-dotenv

# ---- .env file ----
# DATABASE_URL=postgres://localhost:5432/mydb
# SECRET_KEY=super-secret-key-123
# DEBUG=true
# API_KEY=abc123xyz

# ---- Load .env ----
from dotenv import load_dotenv
import os

load_dotenv()    # Loads .env file into os.environ

db_url = os.getenv("DATABASE_URL")
secret = os.getenv("SECRET_KEY")
debug = os.getenv("DEBUG", "false").lower() == "true"    # Convert to bool
api_key = os.getenv("API_KEY")

print(db_url)     # postgres://localhost:5432/mydb
print(debug)      # True

# ---- Load specific file ----
load_dotenv(".env.production")

# ---- With dotenv_values (returns dict, doesn't modify os.environ) ----
from dotenv import dotenv_values

config = dotenv_values(".env")
print(config["DATABASE_URL"])
```

### `.env` File Rules
```
# Comments start with #
KEY=value              # No spaces around =
KEY="value with spaces"  # Quotes for spaces
KEY='single quotes'     # Also works
MULTILINE="line1\nline2"  # \n works in double quotes

# NEVER commit .env to git!
# Add to .gitignore: .env
```

> ğŸ’¡ **Backend essential**: EVERY backend project uses `.env` for secrets. NEVER hardcode passwords, API keys, or database URLs.

---

## 10. `pathlib` Module (Modern Path Handling)

`pathlib` is the **modern** way to handle paths â€” object-oriented, cross-platform.

```python
from pathlib import Path

# ---- Creating paths ----
p = Path(".")                          # Current directory
p = Path("/Users/sid/Documents")       # Absolute
p = Path.home()                        # Home directory
p = Path.cwd()                         # Current working directory

# ---- Path construction (/ operator!) ----
base = Path("/Users/sid")
full = base / "projects" / "myapp" / "config.py"
print(full)    # /Users/sid/projects/myapp/config.py

# ---- Path properties ----
p = Path("/Users/sid/projects/app/main.py")
print(p.name)       # main.py
print(p.stem)       # main
print(p.suffix)     # .py
print(p.parent)     # /Users/sid/projects/app
print(p.parents[0]) # /Users/sid/projects/app
print(p.parents[1]) # /Users/sid/projects
print(p.parts)      # ('/', 'Users', 'sid', 'projects', 'app', 'main.py')
print(p.is_absolute()) # True

# ---- Checking existence ----
p = Path("sample.txt")
print(p.exists())        # True/False
print(p.is_file())       # True/False
print(p.is_dir())        # True/False

# ---- Reading and writing (no open() needed!) ----
p = Path("greeting.txt")
p.write_text("Hello, World!")                  # Write
content = p.read_text()                        # Read
print(content)                                  # Hello, World!

p.write_bytes(b"binary data")                  # Binary write
data = p.read_bytes()                          # Binary read

# ---- Directory operations ----
d = Path("new_folder/sub_folder")
d.mkdir(parents=True, exist_ok=True)           # Like mkdir -p

# List directory
for item in Path(".").iterdir():
    print(f"{'DIR' if item.is_dir() else 'FILE'}: {item.name}")

# ---- Glob (find files by pattern) ----
for py_file in Path(".").glob("*.py"):         # Current dir only
    print(py_file)

for py_file in Path(".").rglob("*.py"):        # Recursive!
    print(py_file)

# ---- Rename / Delete ----
p = Path("old_name.txt")
p.write_text("temp")
p.rename("new_name.txt")                       # Rename
Path("new_name.txt").unlink()                   # Delete file

Path("empty_dir").rmdir()                       # Delete empty directory
```

### `pathlib` vs `os.path` Comparison
| Task | `os.path` (old) | `pathlib` (modern) |
|------|-----------------|-------------------|
| Join paths | `os.path.join(a, b)` | `Path(a) / b` |
| Get filename | `os.path.basename(p)` | `p.name` |
| Get extension | `os.path.splitext(p)[1]` | `p.suffix` |
| Check exists | `os.path.exists(p)` | `p.exists()` |
| Get parent | `os.path.dirname(p)` | `p.parent` |
| Read file | `open(p).read()` | `p.read_text()` |
| Create dir | `os.makedirs(p)` | `p.mkdir(parents=True)` |

> ğŸ’¡ **Best practice**: Use `pathlib` for all new code. It's cleaner and more Pythonic.

---

## 11. `os` Module

```python
import os

# ---- Environment variables ----
print(os.environ.get("HOME"))                  # /Users/sid
print(os.getenv("PATH"))                       # System PATH
os.environ["MY_VAR"] = "hello"                 # Set env var

# ---- Path operations (prefer pathlib, but know os.path) ----
print(os.path.exists("sample.txt"))            # True/False
print(os.path.isfile("sample.txt"))            # True/False
print(os.path.isdir("my_folder"))              # True/False
print(os.path.join("folder", "sub", "file.txt"))  # folder/sub/file.txt
print(os.path.abspath("sample.txt"))           # Full absolute path
print(os.path.basename("/path/to/file.txt"))   # file.txt
print(os.path.dirname("/path/to/file.txt"))    # /path/to
print(os.path.splitext("image.png"))           # ('image', '.png')
print(os.path.getsize("sample.txt"))           # File size in bytes

# ---- Directory operations ----
os.makedirs("new/nested/dir", exist_ok=True)   # Create nested dirs
print(os.listdir("."))                         # List directory contents
print(os.getcwd())                             # Current working directory
os.chdir("/tmp")                               # Change directory (avoid this!)

# ---- File operations ----
os.rename("old.txt", "new.txt")                # Rename
os.remove("file.txt")                          # Delete file
os.rmdir("empty_dir")                          # Delete empty directory

# ---- Walk directory tree ----
for root, dirs, files in os.walk("."):
    for file in files:
        full_path = os.path.join(root, file)
        print(full_path)
```

---

## 12. `shutil` Module (Copy, Move, Delete)

```python
import shutil

# ---- Copy file ----
shutil.copy("source.txt", "dest.txt")          # Copy file (not metadata)
shutil.copy2("source.txt", "dest.txt")         # Copy file + metadata (timestamps)

# ---- Copy directory (recursive) ----
shutil.copytree("src_folder", "dst_folder")    # Copy entire directory
# Python 3.8+: dirs_exist_ok=True to overwrite
shutil.copytree("src", "dst", dirs_exist_ok=True)

# ---- Move file or directory ----
shutil.move("old_path/file.txt", "new_path/file.txt")
shutil.move("old_folder", "new_location/old_folder")

# ---- Delete directory (recursive â€” DANGEROUS!) ----
shutil.rmtree("folder_to_delete")    # Deletes EVERYTHING inside!

# ---- Disk usage ----
usage = shutil.disk_usage("/")
print(f"Total: {usage.total // (1024**3)} GB")
print(f"Used:  {usage.used // (1024**3)} GB")
print(f"Free:  {usage.free // (1024**3)} GB")

# ---- Archive ----
shutil.make_archive("backup", "zip", "my_folder")    # Creates backup.zip
shutil.unpack_archive("backup.zip", "extracted/")     # Extract
```

---

## 13. `tempfile` Module

Create temporary files and directories that auto-cleanup.

```python
import tempfile
import os

# ---- Temporary file (auto-deletes when closed) ----
with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=True) as f:
    f.write("temporary data")
    f.flush()
    print(f.name)    # /tmp/tmp_abc123.txt
    # File exists here
# File DELETED after `with` block

# ---- Keep the temp file (delete=False) ----
with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False) as f:
    f.write("name,age\nSid,25\n")
    temp_path = f.name

print(f"Temp file at: {temp_path}")    # Still exists!
os.remove(temp_path)                    # Manual cleanup

# ---- Temporary directory (auto-deletes) ----
with tempfile.TemporaryDirectory() as tmpdir:
    print(f"Temp dir: {tmpdir}")
    # Create files inside
    with open(os.path.join(tmpdir, "data.txt"), "w") as f:
        f.write("temp data")
# Entire directory DELETED after `with` block

# ---- Get temp directory path ----
print(tempfile.gettempdir())    # /tmp (Linux/Mac) or C:\Users\...\Temp (Windows)
```

### Backend Use Cases
```python
import tempfile

# Download â†’ process â†’ upload (don't pollute disk)
with tempfile.NamedTemporaryFile(suffix=".pdf") as tmp:
    # download_file(url, tmp.name)
    # process_pdf(tmp.name)
    # upload_to_s3(tmp.name)
    pass    # Auto-cleaned!

# Generate reports to temp files
with tempfile.TemporaryDirectory() as tmpdir:
    report_path = os.path.join(tmpdir, "report.csv")
    # generate_report(report_path)
    # email_report(report_path)
    pass    # Whole dir cleaned up!
```

> ğŸ’¡ **Backend tip**: Use `tempfile` for processing uploads, generating reports, and any file that doesn't need to persist.

---

## ğŸ”— Quick Reference

```python
# ---- Reading ----
with open("f.txt", "r") as f:
    content = f.read()           # Entire file
    lines = f.readlines()        # List of lines
    for line in f: ...           # Line by line (memory efficient)

# ---- Writing ----
with open("f.txt", "w") as f:   # Overwrite
    f.write("text\n")
with open("f.txt", "a") as f:   # Append
    f.write("more\n")

# ---- Formats ----
import csv, json, yaml
csv.reader(f) / csv.writer(f)                  # CSV
csv.DictReader(f) / csv.DictWriter(f, fields)  # CSV with headers
json.load(f) / json.dump(data, f)              # JSON file
json.loads(s) / json.dumps(data)               # JSON string
yaml.safe_load(f) / yaml.dump(data, f)         # YAML

# ---- Paths ----
from pathlib import Path
p = Path("dir") / "file.txt"
p.read_text() / p.write_text("data")
p.exists() / p.is_file() / p.is_dir()
p.mkdir(parents=True, exist_ok=True)
list(p.rglob("*.py"))                         # Recursive glob

# ---- File ops ----
import shutil
shutil.copy2(src, dst)                         # Copy with metadata
shutil.copytree(src_dir, dst_dir)              # Copy directory
shutil.move(src, dst)                          # Move
shutil.rmtree(dir)                             # Delete directory

# ---- Temp files ----
import tempfile
with tempfile.NamedTemporaryFile() as f: ...   # Auto-delete file
with tempfile.TemporaryDirectory() as d: ...   # Auto-delete dir

# ---- Environment ----
from dotenv import load_dotenv
load_dotenv()
os.getenv("KEY", "default")
```

---

> ğŸ“ **Phase 5 Complete!** Next: Phase 6 â€” Modules, Packages & Project Structure
