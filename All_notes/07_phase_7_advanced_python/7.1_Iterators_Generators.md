# 7.1 Iterators & Generators ‚Äî Notes

> **Status**: ‚úÖ Completed  
> **Date**: 28 February 2026

---

## 1. Iterator Protocol (`__iter__`, `__next__`)

Every `for` loop in Python uses the **iterator protocol** under the hood.

### How `for` Loop Actually Works
```python
# When you write:
for item in [1, 2, 3]:
    print(item)

# Python actually does this:
my_list = [1, 2, 3]
iterator = iter(my_list)       # Calls my_list.__iter__()
while True:
    try:
        item = next(iterator)  # Calls iterator.__next__()
        print(item)
    except StopIteration:      # No more items
        break
```

### The Two Methods
```python
# __iter__() ‚Üí Returns the iterator object itself
# __next__() ‚Üí Returns the next value, raises StopIteration when done

my_list = [10, 20, 30]
iterator = iter(my_list)       # Get iterator

print(next(iterator))    # 10
print(next(iterator))    # 20
print(next(iterator))    # 30
print(next(iterator))    # ‚ùå StopIteration exception!
```

### What's Iterable vs Iterator?

| Concept | Has `__iter__`? | Has `__next__`? | Example |
|---------|----------------|-----------------|---------|
| **Iterable** | ‚úÖ Yes | ‚ùå No | `list`, `dict`, `str`, `set`, `tuple` |
| **Iterator** | ‚úÖ Yes | ‚úÖ Yes | `iter(list)`, generator objects, `file` |

```python
# list is ITERABLE (has __iter__)
my_list = [1, 2, 3]
print(hasattr(my_list, '__iter__'))    # True
print(hasattr(my_list, '__next__'))    # False ‚Äî NOT an iterator!

# iter(list) returns an ITERATOR (has both)
it = iter(my_list)
print(hasattr(it, '__iter__'))     # True
print(hasattr(it, '__next__'))     # True ‚Äî IS an iterator!
```

### Iterators Are One-Shot
```python
my_list = [1, 2, 3]

# Iterable ‚Üí can iterate multiple times
for x in my_list: print(x)    # 1, 2, 3
for x in my_list: print(x)    # 1, 2, 3 (works again!)

# Iterator ‚Üí ONE-TIME only
it = iter(my_list)
for x in it: print(x)    # 1, 2, 3
for x in it: print(x)    # (nothing ‚Äî exhausted!)
```

---

## 2. Creating Custom Iterators

### Basic Custom Iterator
```python
class CountDown:
    """Iterator that counts down from n to 1."""
    
    def __init__(self, start):
        self.current = start
    
    def __iter__(self):
        return self    # Iterator returns itself
    
    def __next__(self):
        if self.current <= 0:
            raise StopIteration
        value = self.current
        self.current -= 1
        return value

# Usage
for num in CountDown(5):
    print(num)
# 5, 4, 3, 2, 1

# Or manually
cd = CountDown(3)
print(next(cd))    # 3
print(next(cd))    # 2
print(next(cd))    # 1
print(next(cd))    # StopIteration!
```

### Range-Like Iterator
```python
class MyRange:
    """Custom range implementation."""
    
    def __init__(self, start, stop, step=1):
        self.start = start
        self.stop = stop
        self.step = step
    
    def __iter__(self):
        # Return a NEW iterator each time ‚Üí can iterate multiple times!
        return MyRangeIterator(self.start, self.stop, self.step)

class MyRangeIterator:
    def __init__(self, start, stop, step):
        self.current = start
        self.stop = stop
        self.step = step
    
    def __iter__(self):
        return self
    
    def __next__(self):
        if self.current >= self.stop:
            raise StopIteration
        value = self.current
        self.current += self.step
        return value

# Reusable!
r = MyRange(1, 6, 2)
print(list(r))    # [1, 3, 5]
print(list(r))    # [1, 3, 5] ‚Äî works again because __iter__ returns NEW iterator
```

### Backend Example: Paginated API Iterator
```python
class PaginatedAPI:
    """Iterate over paginated API responses."""
    
    def __init__(self, base_url, page_size=100):
        self.base_url = base_url
        self.page_size = page_size
    
    def __iter__(self):
        self.page = 1
        self.done = False
        return self
    
    def __next__(self):
        if self.done:
            raise StopIteration
        
        import requests
        response = requests.get(
            self.base_url,
            params={"page": self.page, "size": self.page_size}
        )
        data = response.json()
        
        if not data["results"]:
            raise StopIteration
        
        self.page += 1
        if not data.get("next"):
            self.done = True
        
        return data["results"]

# Usage ‚Äî fetches pages lazily!
# for page_items in PaginatedAPI("https://api.example.com/users"):
#     for user in page_items:
#         process(user)
```

---

## 3. Generator Functions (Deep Dive)

Generators are the **easy way** to create iterators ‚Äî no class needed!

### Basic Generator
```python
def count_up(n):
    """Generator: yields 1 to n."""
    i = 1
    while i <= n:
        yield i        # Pauses here, returns value
        i += 1         # Resumes here on next call

# Usage ‚Äî same as iterator!
for num in count_up(5):
    print(num)    # 1, 2, 3, 4, 5

# It returns a generator OBJECT
gen = count_up(3)
print(type(gen))        # <class 'generator'>
print(next(gen))        # 1
print(next(gen))        # 2
print(next(gen))        # 3
print(next(gen))        # StopIteration!
```

### How `yield` Works
```python
def my_generator():
    print("Step 1")
    yield "A"              # Pause ‚Üí return "A"
    print("Step 2")        # Resume here
    yield "B"              # Pause ‚Üí return "B"
    print("Step 3")        # Resume here
    yield "C"              # Pause ‚Üí return "C"
    print("Done!")         # Resume here ‚Üí StopIteration

gen = my_generator()
print(next(gen))    # Step 1 ‚Üí "A"
print(next(gen))    # Step 2 ‚Üí "B"
print(next(gen))    # Step 3 ‚Üí "C"
# next(gen)         # Done! ‚Üí StopIteration
```

### Generator Expression (One-Liner)
```python
# List comprehension ‚Üí list (all in memory)
squares_list = [x**2 for x in range(1000000)]    # 8MB+ memory!

# Generator expression ‚Üí lazy (one at a time)
squares_gen = (x**2 for x in range(1000000))     # Almost 0 memory!

# Usage is the same
for sq in squares_gen:
    if sq > 100:
        break

# Can convert to list if needed
first_10 = list(x**2 for x in range(10))    # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

# In function calls ‚Äî no extra parentheses needed
total = sum(x**2 for x in range(100))
max_val = max(len(word) for word in ["hello", "world", "python"])
```

### `yield from` ‚Äî Delegating to Sub-Generator
```python
# Without yield from
def flatten(nested):
    for sublist in nested:
        for item in sublist:
            yield item

# With yield from (cleaner!)
def flatten(nested):
    for sublist in nested:
        yield from sublist    # Delegates to sublist's iterator

print(list(flatten([[1, 2], [3, 4], [5]])))    # [1, 2, 3, 4, 5]

# Combining generators
def gen_a():
    yield 1
    yield 2

def gen_b():
    yield 3
    yield 4

def combined():
    yield from gen_a()    # 1, 2
    yield from gen_b()    # 3, 4

print(list(combined()))    # [1, 2, 3, 4]
```

### `send()` ‚Äî Sending Values INTO Generator
```python
def accumulator():
    total = 0
    while True:
        value = yield total    # yield current total, receive new value
        if value is None:
            break
        total += value

gen = accumulator()
next(gen)             # Initialize (must call next() first!) ‚Üí 0
print(gen.send(10))   # 10 (total = 0 + 10)
print(gen.send(20))   # 30 (total = 10 + 20)
print(gen.send(5))    # 35 (total = 30 + 5)
```

---

## 4. Generator Pipelines

Chain generators together ‚Äî each processes data and passes to the next. Memory efficient!

```python
# Pipeline: Read lines ‚Üí filter non-empty ‚Üí strip whitespace ‚Üí convert to uppercase

def read_lines(filename):
    """Stage 1: Read file line by line."""
    with open(filename) as f:
        for line in f:
            yield line

def strip_lines(lines):
    """Stage 2: Strip whitespace."""
    for line in lines:
        yield line.strip()

def filter_empty(lines):
    """Stage 3: Remove empty lines."""
    for line in lines:
        if line:
            yield line

def to_upper(lines):
    """Stage 4: Convert to uppercase."""
    for line in lines:
        yield line.upper()

# Chain them together ‚Äî NO intermediate lists!
pipeline = to_upper(filter_empty(strip_lines(read_lines("data.txt"))))

for line in pipeline:
    print(line)
# Each line flows through ALL stages, one at a time ‚Üí minimal memory!
```

### Backend Example: Log Processing Pipeline
```python
def read_logs(log_file):
    """Read log entries."""
    with open(log_file) as f:
        for line in f:
            yield line.strip()

def parse_log(lines):
    """Parse each log line into a dict."""
    for line in lines:
        parts = line.split(" | ")
        if len(parts) >= 3:
            yield {
                "timestamp": parts[0],
                "level": parts[1],
                "message": parts[2],
            }

def filter_errors(entries):
    """Only pass ERROR entries."""
    for entry in entries:
        if entry["level"] == "ERROR":
            yield entry

def format_alert(entries):
    """Format for alerting."""
    for entry in entries:
        yield f"üö® [{entry['timestamp']}] {entry['message']}"

# Process 10GB log file with constant memory!
alerts = format_alert(filter_errors(parse_log(read_logs("server.log"))))
for alert in alerts:
    send_to_slack(alert)
```

---

## 5. Lazy Evaluation Concept

**Lazy** = compute only when needed. **Eager** = compute everything upfront.

```python
# ---- Eager (all at once) ----
data = [x**2 for x in range(10_000_000)]    # Computes ALL 10M squares NOW
# Uses ~80MB RAM, takes seconds to create
result = data[0]    # Fast lookup

# ---- Lazy (on demand) ----
data = (x**2 for x in range(10_000_000))    # Computes NOTHING yet
# Uses ~0 RAM, instant creation
result = next(data)    # Computes just ONE square

# ---- Python lazy objects ----
# range()     ‚Üí lazy (doesn't create list of numbers)
# map()       ‚Üí lazy
# filter()    ‚Üí lazy
# zip()       ‚Üí lazy
# open(file)  ‚Üí lazy (reads line by line)
# generators  ‚Üí lazy

# ---- When to be lazy ----
# ‚úÖ Large data ‚Üí use generators/lazy
# ‚úÖ Might not need all items ‚Üí lazy
# ‚úÖ Data streams (logs, API pages) ‚Üí lazy
# ‚ùå Need random access (data[500]) ‚Üí eager (list)
# ‚ùå Need to iterate multiple times ‚Üí eager (list)
# ‚ùå Small data ‚Üí doesn't matter
```

### Lazy in Backend
```python
# ‚ùå Bad: Load all users from DB into memory
users = list(User.objects.all())    # 1M users ‚Üí 1GB RAM!

# ‚úÖ Good: Django QuerySets are LAZY
users = User.objects.filter(active=True)    # No DB query yet!
users = users.order_by("name")              # Still no query!
for user in users:                          # NOW the query runs
    process(user)                           # Fetches in batches

# ‚úÖ Good: Use iterator() for large querysets
for user in User.objects.all().iterator(chunk_size=2000):
    process(user)    # Fetches 2000 at a time
```

---

## 6. `itertools` Mastery

`itertools` provides **fast, memory-efficient** tools for iterators.

### Infinite Iterators
```python
from itertools import count, cycle, repeat

# ---- count(start, step) ‚Äî infinite counter ----
for i in count(10, 2):    # 10, 12, 14, 16, ...
    if i > 20:
        break
    print(i)

# ---- cycle(iterable) ‚Äî infinite loop over items ----
colors = cycle(["red", "green", "blue"])
for _, color in zip(range(7), colors):
    print(color)    # red, green, blue, red, green, blue, red

# ---- repeat(value, times) ‚Äî repeat a value ----
print(list(repeat("hello", 3)))    # ['hello', 'hello', 'hello']
print(list(repeat(0, 5)))          # [0, 0, 0, 0, 0]
```

### Combinatorics
```python
from itertools import product, permutations, combinations, combinations_with_replacement

# ---- product ‚Äî cartesian product (nested for loops) ----
print(list(product("AB", "12")))
# [('A','1'), ('A','2'), ('B','1'), ('B','2')]

print(list(product(range(2), repeat=3)))
# [(0,0,0), (0,0,1), (0,1,0), (0,1,1), (1,0,0), (1,0,1), (1,1,0), (1,1,1)]

# ---- permutations ‚Äî order matters ----
print(list(permutations("ABC", 2)))
# [('A','B'), ('A','C'), ('B','A'), ('B','C'), ('C','A'), ('C','B')]

# ---- combinations ‚Äî order doesn't matter ----
print(list(combinations("ABC", 2)))
# [('A','B'), ('A','C'), ('B','C')]

# ---- combinations_with_replacement ‚Äî can reuse ----
print(list(combinations_with_replacement("AB", 2)))
# [('A','A'), ('A','B'), ('B','B')]
```

### Filtering & Selecting
```python
from itertools import islice, takewhile, dropwhile, filterfalse, compress

# ---- islice ‚Äî slice an iterator ----
from itertools import count
print(list(islice(count(0), 5)))         # [0, 1, 2, 3, 4]
print(list(islice(count(0), 2, 8, 2)))   # [2, 4, 6] (start=2, stop=8, step=2)

# ---- takewhile ‚Äî take while condition is True ----
nums = [2, 4, 6, 7, 8, 10]
print(list(takewhile(lambda x: x % 2 == 0, nums)))    # [2, 4, 6]

# ---- dropwhile ‚Äî skip while condition is True ----
print(list(dropwhile(lambda x: x % 2 == 0, nums)))    # [7, 8, 10]

# ---- filterfalse ‚Äî opposite of filter ----
print(list(filterfalse(lambda x: x > 5, nums)))    # [2, 4]

# ---- compress ‚Äî select by mask ----
data = ["a", "b", "c", "d", "e"]
mask = [1, 0, 1, 0, 1]
print(list(compress(data, mask)))    # ['a', 'c', 'e']
```

### Chaining & Grouping
```python
from itertools import chain, groupby, zip_longest, starmap, accumulate

# ---- chain ‚Äî combine multiple iterables ----
a = [1, 2, 3]
b = [4, 5, 6]
c = [7, 8]
print(list(chain(a, b, c)))    # [1, 2, 3, 4, 5, 6, 7, 8]

# chain.from_iterable ‚Äî flatten one level
nested = [[1, 2], [3, 4], [5]]
print(list(chain.from_iterable(nested)))    # [1, 2, 3, 4, 5]

# ---- groupby ‚Äî group consecutive items (MUST be sorted first!) ----
data = [
    {"city": "Mumbai", "name": "Rahul"},
    {"city": "Mumbai", "name": "Priya"},
    {"city": "Delhi", "name": "Sid"},
    {"city": "Delhi", "name": "Amit"},
]
data.sort(key=lambda x: x["city"])    # MUST sort first!

for city, group in groupby(data, key=lambda x: x["city"]):
    members = list(group)
    print(f"{city}: {[m['name'] for m in members]}")
# Delhi: ['Sid', 'Amit']
# Mumbai: ['Rahul', 'Priya']

# ---- zip_longest ‚Äî zip with fill value ----
a = [1, 2, 3]
b = ["a", "b"]
print(list(zip_longest(a, b, fillvalue="-")))    # [(1,'a'), (2,'b'), (3,'-')]

# ---- starmap ‚Äî map with unpacking ----
pairs = [(2, 3), (4, 5), (6, 7)]
print(list(starmap(pow, pairs)))    # [8, 1024, 279936]  (2¬≥, 4‚Åµ, 6‚Å∑)

# ---- accumulate ‚Äî running totals ----
import operator
nums = [1, 2, 3, 4, 5]
print(list(accumulate(nums)))                        # [1, 3, 6, 10, 15]
print(list(accumulate(nums, operator.mul)))           # [1, 2, 6, 24, 120]
print(list(accumulate(nums, max)))                    # [1, 2, 3, 4, 5]
```

---

## 7. Memory Efficiency with Generators

### Memory Comparison
```python
import sys

# List ‚Äî stores ALL items in memory
big_list = [x for x in range(1_000_000)]
print(sys.getsizeof(big_list))    # ~8,448,728 bytes (8MB)

# Generator ‚Äî stores only the logic
big_gen = (x for x in range(1_000_000))
print(sys.getsizeof(big_gen))     # ~200 bytes (0.0002MB!)

# range ‚Äî also lazy!
big_range = range(1_000_000)
print(sys.getsizeof(big_range))   # 48 bytes!
```

### Real-World Memory Savings
```python
# ‚ùå BAD: Read entire file into memory
def process_file_bad(filename):
    with open(filename) as f:
        lines = f.readlines()          # ALL lines in memory!
    for line in lines:
        yield line.upper()

# ‚úÖ GOOD: Process line by line
def process_file_good(filename):
    with open(filename) as f:
        for line in f:                 # One line at a time
            yield line.upper()

# ‚ùå BAD: Collect all results then return
def get_all_users_bad():
    users = []
    for page in range(1000):
        page_users = fetch_page(page)  # API call
        users.extend(page_users)       # Accumulate ALL
    return users                       # 1M users in memory!

# ‚úÖ GOOD: Yield results as they come
def get_all_users_good():
    for page in range(1000):
        page_users = fetch_page(page)
        yield from page_users          # Yield each user, constant memory
```

### When to Use What

| Scenario | Use | Why |
|----------|-----|-----|
| Small data (<1000 items) | List | Random access, simple |
| Large data (millions) | Generator | Memory efficient |
| Need `len()`, indexing | List | Generators don't support |
| Stream/pipeline processing | Generator | Process one at a time |
| Multiple iterations needed | List | Generators are one-shot |
| File processing | Generator | Don't load entire file |
| API pagination | Generator | Fetch on demand |

---

## üîó Quick Reference

```python
# ---- Iterator Protocol ----
class MyIter:
    def __iter__(self): return self
    def __next__(self): raise StopIteration

# ---- Generator Function ----
def gen():
    yield 1
    yield 2

# ---- Generator Expression ----
g = (x**2 for x in range(10))

# ---- yield from ----
def combined():
    yield from gen_a()
    yield from gen_b()

# ---- Key itertools ----
from itertools import (
    chain,              # Combine iterables
    islice,             # Slice iterator
    groupby,            # Group consecutive items
    product,            # Cartesian product
    permutations,       # All orderings
    combinations,       # All subsets (no repeat)
    count, cycle,       # Infinite iterators
    accumulate,         # Running totals
    zip_longest,        # Zip with fill
    takewhile,          # Take while True
    dropwhile,          # Drop while True
    starmap,            # Map with unpacking
)

# ---- Memory rule ----
# List:      [x for x in big_data]    ‚Üí ALL in memory
# Generator: (x for x in big_data)    ‚Üí ONE at a time
```

---

> üìù **Next up**: 7.2 Decorators Deep Dive ‚Äî Function/class decorators, factories, real-world patterns
