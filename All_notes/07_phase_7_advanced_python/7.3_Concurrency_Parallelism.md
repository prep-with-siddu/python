# 7.3 Concurrency & Parallelism ‚Äî Notes

> **Status**: ‚úÖ Completed  
> **Date**: 28 February 2026

---

## 1. GIL (Global Interpreter Lock)

The GIL is the **most important** concept to understand for Python concurrency.

### What Is The GIL?
```python
# The GIL is a mutex (lock) in CPython that allows only ONE thread
# to execute Python bytecode at a time.

# Even with multiple threads, only ONE runs at any moment!

#   Thread 1: ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà   (runs, waits, runs, waits, runs)
#   Thread 2: ‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë   (waits, runs, waits, runs, waits)
#   GIL:      111222111222111   (switches between threads)

# WHY does the GIL exist?
# - Simplifies memory management (reference counting is thread-safe)
# - Makes C extensions easier to write
# - Makes single-threaded code faster
```

### GIL Impact

| Task Type | GIL Impact | Solution |
|-----------|-----------|----------|
| **CPU-bound** (math, processing) | Threads are USELESS ‚ùå | Use `multiprocessing` |
| **I/O-bound** (network, file, DB) | Threads work fine ‚úÖ | Use `threading` or `asyncio` |

```python
# CPU-bound: GIL makes threads slower than single-threaded!
# - Number crunching, image processing, data parsing
# ‚Üí Use multiprocessing (separate processes, each with own GIL)

# I/O-bound: GIL is released during I/O waits!
# - API calls, database queries, file reads, network requests
# ‚Üí Use threading or asyncio (GIL released while waiting)
```

---

## 2. Threading (`threading` Module)

Best for **I/O-bound** tasks (API calls, DB queries, file I/O).

```python
import threading
import time

def download(url, delay):
    print(f"Downloading {url}...")
    time.sleep(delay)    # Simulating I/O wait
    print(f"Done: {url}")

# ---- Create and start threads ----
t1 = threading.Thread(target=download, args=("page1.html", 2))
t2 = threading.Thread(target=download, args=("page2.html", 3))
t3 = threading.Thread(target=download, args=("page3.html", 1))

start = time.time()
t1.start()    # Start thread (non-blocking)
t2.start()
t3.start()

t1.join()     # Wait for t1 to finish
t2.join()     # Wait for t2 to finish
t3.join()     # Wait for t3 to finish

print(f"Total: {time.time() - start:.1f}s")
# ~3s (parallel) instead of ~6s (sequential)!

# ---- Daemon threads (die when main program exits) ----
t = threading.Thread(target=download, args=("bg.html", 10), daemon=True)
t.start()
# If main exits, daemon thread is killed immediately
```

---

## 3. Thread Synchronization

### `Lock` ‚Äî Prevent Race Conditions
```python
import threading

counter = 0
lock = threading.Lock()

def increment(n):
    global counter
    for _ in range(n):
        # ‚ùå Without lock: race condition! counter ends up wrong
        # counter += 1
        
        # ‚úÖ With lock: safe
        with lock:           # Acquire lock ‚Üí other threads wait
            counter += 1     # Only one thread at a time
                             # Release lock ‚Üí other threads can proceed

threads = [threading.Thread(target=increment, args=(100000,)) for _ in range(5)]
for t in threads: t.start()
for t in threads: t.join()

print(counter)    # 500000 (always correct with lock!)
```

### `RLock` ‚Äî Reentrant Lock (Same Thread Can Acquire Again)
```python
rlock = threading.RLock()

def outer():
    with rlock:          # Acquire
        print("outer")
        inner()          # Can acquire AGAIN (same thread)

def inner():
    with rlock:          # Re-acquire (OK with RLock, deadlock with Lock!)
        print("inner")
```

### `Semaphore` ‚Äî Limit Concurrent Access
```python
import threading
import time

# Allow max 3 threads at a time
semaphore = threading.Semaphore(3)

def access_resource(thread_id):
    with semaphore:    # Only 3 threads can be here simultaneously
        print(f"Thread {thread_id} accessing resource")
        time.sleep(2)
        print(f"Thread {thread_id} done")

threads = [threading.Thread(target=access_resource, args=(i,)) for i in range(10)]
for t in threads: t.start()
# Only 3 run at once, rest wait
```

### `Event` ‚Äî Signal Between Threads
```python
import threading

event = threading.Event()

def waiter():
    print("Waiting for signal...")
    event.wait()              # Blocks until event is set
    print("Signal received! Proceeding...")

def setter():
    import time
    time.sleep(2)
    print("Setting signal!")
    event.set()               # Unblocks all waiters

threading.Thread(target=waiter).start()
threading.Thread(target=setter).start()
```

---

## 4. Thread Pools (`ThreadPoolExecutor`)

Easier than managing threads manually.

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

def fetch_url(url):
    time.sleep(1)    # Simulate network I/O
    return f"Data from {url}"

urls = [f"https://api.example.com/page/{i}" for i in range(10)]

# ---- Using ThreadPoolExecutor ----
with ThreadPoolExecutor(max_workers=5) as executor:
    # submit() ‚Äî returns Future objects
    futures = {executor.submit(fetch_url, url): url for url in urls}
    
    for future in as_completed(futures):    # Process as they complete
        url = futures[future]
        try:
            data = future.result()
            print(f"{url}: {data}")
        except Exception as e:
            print(f"{url} failed: {e}")

# ---- Using map() ‚Äî simpler, ordered results ----
with ThreadPoolExecutor(max_workers=5) as executor:
    results = executor.map(fetch_url, urls)    # Returns results in ORDER
    for result in results:
        print(result)
```

---

## 5. Multiprocessing (`multiprocessing` Module)

Best for **CPU-bound** tasks. Each process has its own GIL!

```python
import multiprocessing
import os

def cpu_intensive(n):
    """CPU-bound: calculate sum of squares."""
    print(f"Process {os.getpid()} calculating...")
    return sum(i**2 for i in range(n))

# ---- Create processes ----
if __name__ == "__main__":    # REQUIRED on macOS/Windows!
    p1 = multiprocessing.Process(target=cpu_intensive, args=(10_000_000,))
    p2 = multiprocessing.Process(target=cpu_intensive, args=(10_000_000,))
    
    p1.start()
    p2.start()
    p1.join()
    p2.join()
```

### Sharing Data Between Processes
```python
from multiprocessing import Process, Value, Array, Queue

# ---- Shared Value ----
counter = Value('i', 0)    # 'i' = integer, initial 0

def increment(shared_counter, n):
    for _ in range(n):
        with shared_counter.get_lock():
            shared_counter.value += 1

# ---- Queue (message passing ‚Äî PREFERRED!) ----
def producer(q):
    for i in range(5):
        q.put(f"item_{i}")
    q.put(None)    # Sentinel: signal done

def consumer(q):
    while True:
        item = q.get()
        if item is None:
            break
        print(f"Got: {item}")

if __name__ == "__main__":
    q = Queue()
    p = Process(target=producer, args=(q,))
    c = Process(target=consumer, args=(q,))
    p.start()
    c.start()
    p.join()
    c.join()
```

---

## 6. Process Pools (`ProcessPoolExecutor`)

```python
from concurrent.futures import ProcessPoolExecutor
import math

def is_prime(n):
    if n < 2: return False
    for i in range(2, int(math.sqrt(n)) + 1):
        if n % i == 0: return False
    return True

numbers = [112272535095293, 112582705942171, 115280095190773, 115797848077099]

if __name__ == "__main__":
    with ProcessPoolExecutor(max_workers=4) as executor:
        results = executor.map(is_prime, numbers)
        for num, prime in zip(numbers, results):
            print(f"{num}: {'prime' if prime else 'not prime'}")
```

---

## 7. `concurrent.futures` ‚Äî `submit`, `map`, `as_completed`

```python
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed

# ---- submit() ‚Üí returns Future ----
with ThreadPoolExecutor(max_workers=3) as executor:
    future = executor.submit(pow, 2, 10)    # Submit single task
    print(future.result())                   # 1024

# ---- map() ‚Üí ordered results ----
with ThreadPoolExecutor(max_workers=3) as executor:
    results = list(executor.map(str.upper, ["hello", "world"]))
    print(results)    # ['HELLO', 'WORLD']

# ---- as_completed() ‚Üí results as they finish (fastest first) ----
import time, random

def task(name):
    delay = random.uniform(0.5, 3)
    time.sleep(delay)
    return f"{name} done in {delay:.1f}s"

with ThreadPoolExecutor(max_workers=5) as executor:
    futures = [executor.submit(task, f"Task-{i}") for i in range(5)]
    
    for future in as_completed(futures):
        print(future.result())    # Fastest task prints first!

# ---- Exception handling ----
with ThreadPoolExecutor() as executor:
    future = executor.submit(int, "not_a_number")
    try:
        result = future.result(timeout=5)    # Timeout in seconds
    except ValueError as e:
        print(f"Error: {e}")
    except TimeoutError:
        print("Task timed out!")
```

---

## 8. `asyncio` ‚Äî async/await Fundamentals

`asyncio` is Python's built-in **single-threaded** concurrency framework. Perfect for I/O-bound tasks.

```python
import asyncio

# ---- Coroutine (async function) ----
async def greet(name, delay):
    print(f"Hello, {name}!")
    await asyncio.sleep(delay)    # Non-blocking sleep! (NOT time.sleep!)
    print(f"Goodbye, {name}!")
    return f"{name} done"

# ---- Running a coroutine ----
asyncio.run(greet("Sid", 1))    # Entry point

# ---- Running multiple concurrently ----
async def main():
    # These run CONCURRENTLY (not sequentially!)
    results = await asyncio.gather(
        greet("Sid", 2),
        greet("Rahul", 1),
        greet("Priya", 3),
    )
    print(results)    # ['Sid done', 'Rahul done', 'Priya done']

asyncio.run(main())    # Total: ~3s (not 6s!)
```

### Key Concept: `await`
```python
# `await` means: "Pause THIS coroutine, let others run, come back when ready"

async def fetch_data(url):
    print(f"Fetching {url}...")
    await asyncio.sleep(1)          # ‚Üê CPU is FREE to run other coroutines!
    print(f"Got {url}")
    return {"url": url, "data": "..."}

# ‚ùå NEVER use blocking calls in async code!
# time.sleep(1)      ‚Üí Blocks everything!
# requests.get(url)  ‚Üí Blocks everything!

# ‚úÖ Use async alternatives
# await asyncio.sleep(1)             ‚Üí Non-blocking
# await aiohttp.get(url)             ‚Üí Non-blocking
# await asyncpg.connect(...)         ‚Üí Non-blocking
```

---

## 9. `asyncio` ‚Äî Event Loop, Tasks, Coroutines

### Event Loop
```python
import asyncio

# The event loop is the brain ‚Äî it decides which coroutine runs next

# asyncio.run() creates and manages the event loop
async def main():
    print("Running in event loop!")

asyncio.run(main)    # Creates loop ‚Üí runs main ‚Üí closes loop

# Get running loop (from inside async code)
async def show_loop():
    loop = asyncio.get_running_loop()
    print(loop)
```

### Tasks (Run in Background)
```python
async def long_task(name, seconds):
    await asyncio.sleep(seconds)
    return f"{name} completed"

async def main():
    # ---- Create tasks (start immediately in background!) ----
    task1 = asyncio.create_task(long_task("A", 2))
    task2 = asyncio.create_task(long_task("B", 3))
    
    # Do other work while tasks run...
    print("Tasks started, doing other work...")
    await asyncio.sleep(1)
    print("Other work done!")
    
    # Now wait for results
    result1 = await task1
    result2 = await task2
    print(result1, result2)

asyncio.run(main())
```

---

## 10. `asyncio` ‚Äî `gather`, `wait`, `create_task`, `run`

### `asyncio.gather()` ‚Äî Run and Collect Results
```python
async def fetch(url):
    await asyncio.sleep(1)
    return f"data from {url}"

async def main():
    # Run all concurrently, get results in ORDER
    results = await asyncio.gather(
        fetch("url1"),
        fetch("url2"),
        fetch("url3"),
    )
    print(results)    # ['data from url1', 'data from url2', 'data from url3']
    
    # With error handling
    results = await asyncio.gather(
        fetch("url1"),
        fetch("url2"),
        return_exceptions=True    # Don't crash on errors, return them
    )
```

### `asyncio.wait()` ‚Äî More Control
```python
async def main():
    tasks = [
        asyncio.create_task(fetch(f"url{i}")) for i in range(5)
    ]
    
    # Wait for first completed
    done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)
    for task in done:
        print(task.result())
    
    # Wait for ALL
    done, pending = await asyncio.wait(tasks, return_when=asyncio.ALL_COMPLETED)
    
    # Wait with timeout
    done, pending = await asyncio.wait(tasks, timeout=5.0)
    for task in pending:
        task.cancel()    # Cancel tasks that didn't finish
```

### `asyncio.wait_for()` ‚Äî Single Task with Timeout
```python
async def main():
    try:
        result = await asyncio.wait_for(fetch("url"), timeout=5.0)
    except asyncio.TimeoutError:
        print("Request timed out!")
```

---

## 11. `asyncio` ‚Äî `Queue`, `Lock`, `Semaphore`

### Async Queue (Producer-Consumer Pattern)
```python
import asyncio

async def producer(queue):
    for i in range(10):
        await queue.put(f"item-{i}")
        print(f"Produced item-{i}")
        await asyncio.sleep(0.1)
    await queue.put(None)    # Signal done

async def consumer(queue, name):
    while True:
        item = await queue.get()
        if item is None:
            await queue.put(None)    # Pass sentinel to other consumers
            break
        print(f"{name} consumed {item}")
        await asyncio.sleep(0.2)
        queue.task_done()

async def main():
    queue = asyncio.Queue(maxsize=5)    # Backpressure: producer waits if full
    
    await asyncio.gather(
        producer(queue),
        consumer(queue, "Worker-1"),
        consumer(queue, "Worker-2"),
    )

asyncio.run(main())
```

### Async Lock & Semaphore
```python
# Async Lock
lock = asyncio.Lock()

async def safe_update(shared_data):
    async with lock:    # Only one coroutine at a time
        value = shared_data["count"]
        await asyncio.sleep(0.1)    # Simulate async work
        shared_data["count"] = value + 1

# Async Semaphore (limit concurrent operations)
semaphore = asyncio.Semaphore(10)    # Max 10 concurrent

async def limited_fetch(url):
    async with semaphore:    # Only 10 at a time
        return await fetch(url)

async def main():
    urls = [f"https://api.com/page/{i}" for i in range(100)]
    results = await asyncio.gather(*[limited_fetch(url) for url in urls])
```

---

## 12. `aiohttp` for Async HTTP Requests

```python
# pip install aiohttp
import aiohttp
import asyncio

async def fetch_url(session, url):
    async with session.get(url) as response:
        return await response.json()

async def main():
    async with aiohttp.ClientSession() as session:
        # Fetch multiple URLs concurrently!
        urls = [f"https://jsonplaceholder.typicode.com/posts/{i}" for i in range(1, 6)]
        
        tasks = [fetch_url(session, url) for url in urls]
        results = await asyncio.gather(*tasks)
        
        for post in results:
            print(f"Post {post['id']}: {post['title'][:50]}")

asyncio.run(main())
# Fetches 5 posts concurrently ‚Äî much faster than sequential!
```

---

## 13. `aiofiles` for Async File Operations

```python
# pip install aiofiles
import aiofiles
import asyncio

async def read_file(filename):
    async with aiofiles.open(filename, "r") as f:
        content = await f.read()
        return content

async def write_file(filename, data):
    async with aiofiles.open(filename, "w") as f:
        await f.write(data)

async def main():
    await write_file("output.txt", "Hello, async world!")
    content = await read_file("output.txt")
    print(content)

asyncio.run(main())
```

---

## 14. `asyncpg` for Async PostgreSQL

```python
# pip install asyncpg
import asyncpg
import asyncio

async def main():
    # Connect
    conn = await asyncpg.connect(
        host="localhost", port=5432,
        user="postgres", password="password",
        database="mydb"
    )
    
    # Query
    rows = await conn.fetch("SELECT id, name FROM users WHERE active = $1", True)
    for row in rows:
        print(f"User {row['id']}: {row['name']}")
    
    # Single row
    user = await conn.fetchrow("SELECT * FROM users WHERE id = $1", 1)
    
    # Execute (INSERT/UPDATE/DELETE)
    await conn.execute(
        "INSERT INTO users(name, email) VALUES($1, $2)",
        "Sid", "sid@example.com"
    )
    
    # Connection pool (for production!)
    pool = await asyncpg.create_pool(
        host="localhost", database="mydb",
        min_size=5, max_size=20
    )
    
    async with pool.acquire() as conn:
        rows = await conn.fetch("SELECT * FROM users")
    
    await pool.close()
    await conn.close()

asyncio.run(main())
```

---

## 15. When to Use Threading vs Multiprocessing vs Asyncio

```
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Is the task   ‚îÇ
         ‚îÇ   I/O-bound?    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê
             YES      NO
              ‚îÇ        ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ Need many ‚îÇ   ‚îÇ CPU-bound  ‚îÇ
     ‚îÇ concurrent‚îÇ   ‚îÇ    task     ‚îÇ
     ‚îÇ connections‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ   (100+)? ‚îÇ         ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   multiprocessing
       ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê
      YES      NO
       ‚îÇ        ‚îÇ
    asyncio  threading
```

| Feature | `threading` | `multiprocessing` | `asyncio` |
|---------|------------|-------------------|-----------|
| Best for | I/O-bound (few tasks) | CPU-bound | I/O-bound (many tasks) |
| GIL impact | Released during I/O ‚úÖ | No GIL (separate processes) ‚úÖ | Single thread ‚úÖ |
| Memory | Shared | Separate (heavy) | Shared (light) |
| Overhead | Medium | High | **Low** |
| Scalability | ~100 threads | ~CPU cores | **10,000+ connections** |
| Complexity | Medium | Medium | Higher |
| Race conditions | Yes (need locks) | Less (separate memory) | Less (cooperative) |
| Use case | File I/O, few API calls | Data processing, ML | Web servers, APIs |

### Real-World Choices
```python
# ---- Web scraping (many HTTP calls) ‚Üí asyncio ----
async def scrape():
    async with aiohttp.ClientSession() as session:
        urls = [...]    # 1000 URLs
        results = await asyncio.gather(*[fetch(session, url) for url in urls])

# ---- Image processing ‚Üí multiprocessing ----
from concurrent.futures import ProcessPoolExecutor
with ProcessPoolExecutor() as executor:
    results = executor.map(process_image, image_paths)

# ---- File watching + processing ‚Üí threading ----
import threading
watcher = threading.Thread(target=watch_directory, daemon=True)
processor = threading.Thread(target=process_queue, daemon=True)
```

---

## 16. `uvloop` (Faster Event Loop)

```python
# pip install uvloop
# Drop-in replacement for asyncio event loop ‚Äî 2-4x faster!

import asyncio
import uvloop

# Method 1: Set as default
asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
asyncio.run(main())

# Method 2: Use uvloop.run() (Python 3.12+)
uvloop.run(main())

# FastAPI + Uvicorn already uses uvloop by default!
# uvicorn main:app ‚Üí uses uvloop automatically
```

---

## üîó Quick Reference

```python
# ---- Threading (I/O-bound, few tasks) ----
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=10) as executor:
    results = executor.map(fetch, urls)

# ---- Multiprocessing (CPU-bound) ----
from concurrent.futures import ProcessPoolExecutor
with ProcessPoolExecutor() as executor:
    results = executor.map(process, data)

# ---- Asyncio (I/O-bound, many tasks) ----
import asyncio

async def main():
    results = await asyncio.gather(task1(), task2(), task3())

asyncio.run(main())

# ---- Thread safety ----
lock = threading.Lock()
with lock: shared_resource += 1

# ---- Async concurrency limit ----
sem = asyncio.Semaphore(10)
async with sem: await fetch(url)
```

---

> üìù **Next up**: 7.4 Memory Management ‚Äî Reference counting, GC, weak refs, profiling
