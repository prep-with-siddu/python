# 7.4 Memory Management â€” Notes

> **Status**: âœ… Completed  
> **Date**: 28 February 2026

---

## 1. How Python Manages Memory (Reference Counting + Garbage Collection)

### Reference Counting (Primary Mechanism)
```python
import sys

# Every object has a reference count
a = [1, 2, 3]           # refcount = 1 (a points to it)
b = a                    # refcount = 2 (a and b point to same object)
c = a                    # refcount = 3

print(sys.getrefcount(a))    # 4 (3 + 1 temporary from function call)

del b                    # refcount = 2
c = None                 # refcount = 1
del a                    # refcount = 0 â†’ IMMEDIATELY freed!

# When refcount reaches 0 â†’ object is deallocated instantly
# No need to wait for GC!
```

### The Circular Reference Problem
```python
# Reference counting FAILS for circular references!
class Node:
    def __init__(self):
        self.parent = None
        self.children = []

a = Node()        # a refcount = 1
b = Node()        # b refcount = 1
a.children.append(b)    # b refcount = 2
b.parent = a             # a refcount = 2

del a    # a refcount = 1 (still referenced by b.parent!)
del b    # b refcount = 1 (still referenced by a.children!)
# Both objects have refcount > 0 â†’ CAN'T be freed by refcounting!
# This is a MEMORY LEAK without garbage collection!
```

### Garbage Collector (Cycle Detector)
```python
import gc

# Python's GC handles circular references
# Uses "generational" garbage collection:
#   Generation 0: New objects (collected most often)
#   Generation 1: Survived 1 GC cycle
#   Generation 2: Long-lived objects (collected least often)

# GC runs automatically, but you can control it:
gc.collect()              # Force a collection
gc.disable()              # Disable automatic GC (rare!)
gc.enable()               # Re-enable

# Check GC thresholds
print(gc.get_threshold())    # (700, 10, 10)
# Gen 0 collects after 700 new allocations
# Gen 1 collects every 10 Gen 0 collections
# Gen 2 collects every 10 Gen 1 collections

# See what GC tracks
print(gc.get_count())    # (123, 5, 1) â€” objects in each generation
```

### Memory Lifecycle
```
Object Created â†’ Reference Counting Tracks It
    â”‚
    â”œâ”€â”€ refcount drops to 0 â†’ IMMEDIATELY freed (most objects)
    â”‚
    â””â”€â”€ Circular reference? â†’ Garbage Collector finds and frees it
```

---

## 2. `gc` Module

```python
import gc

# ---- Force garbage collection ----
collected = gc.collect()    # Returns number of unreachable objects found
print(f"Collected {collected} objects")

# ---- Get all objects tracked by GC ----
all_objects = gc.get_objects()
print(f"GC tracking {len(all_objects)} objects")

# ---- Find what refers to an object ----
x = [1, 2, 3]
referrers = gc.get_referrers(x)
print(f"x has {len(referrers)} referrers")

# ---- Find what an object refers to ----
class MyClass:
    def __init__(self):
        self.data = [1, 2, 3]

obj = MyClass()
referents = gc.get_referents(obj)
print(referents)    # [{'data': [1, 2, 3]}] â€” its __dict__

# ---- Debug GC ----
gc.set_debug(gc.DEBUG_STATS)    # Print GC stats
gc.collect()
gc.set_debug(0)                 # Turn off

# ---- Freeze objects (Python 3.7+) ----
gc.freeze()        # Move all objects to permanent generation (skip GC)
# Useful after startup in long-running servers
```

### Backend Tip: GC Tuning
```python
# For high-performance servers, some teams disable GC
# and run it manually during low-traffic periods

import gc

# Disable automatic GC
gc.disable()

# Run manually every N requests or on a schedule
def periodic_gc():
    gc.collect()
    # Log: print(f"GC collected, tracking {len(gc.get_objects())} objects")
```

---

## 3. `sys.getsizeof()`

```python
import sys

# ---- Size of objects (in bytes) ----
print(sys.getsizeof(0))           # 28 bytes (int)
print(sys.getsizeof(1))           # 28 bytes
print(sys.getsizeof(10**100))     # 72 bytes (big int needs more)

print(sys.getsizeof(""))          # 49 bytes (empty string overhead)
print(sys.getsizeof("hello"))     # 54 bytes
print(sys.getsizeof("a" * 1000)) # 1049 bytes

print(sys.getsizeof([]))          # 56 bytes (empty list)
print(sys.getsizeof([1,2,3]))     # 88 bytes
print(sys.getsizeof(list(range(1000))))  # ~8056 bytes

print(sys.getsizeof({}))          # 64 bytes (empty dict)
print(sys.getsizeof(set()))       # 216 bytes (empty set)
print(sys.getsizeof(()))          # 40 bytes (empty tuple)

# âš ï¸ WARNING: getsizeof only shows SHALLOW size!
# It does NOT include the size of contained objects!
nested = [[1,2,3], [4,5,6], [7,8,9]]
print(sys.getsizeof(nested))       # ~88 bytes (just the outer list!)
# Real total is much more (outer list + 3 inner lists + 9 ints)
```

### Deep Size Calculation
```python
import sys

def deep_getsizeof(obj, seen=None):
    """Recursively calculate total size of an object."""
    if seen is None:
        seen = set()
    
    obj_id = id(obj)
    if obj_id in seen:
        return 0
    seen.add(obj_id)
    
    size = sys.getsizeof(obj)
    
    if isinstance(obj, dict):
        size += sum(deep_getsizeof(k, seen) + deep_getsizeof(v, seen)
                    for k, v in obj.items())
    elif isinstance(obj, (list, tuple, set, frozenset)):
        size += sum(deep_getsizeof(item, seen) for item in obj)
    
    return size

data = {"users": [{"name": "Sid", "scores": [1, 2, 3]}]}
print(f"Shallow: {sys.getsizeof(data)} bytes")
print(f"Deep: {deep_getsizeof(data)} bytes")
```

---

## 4. Weak References (`weakref`)

A weak reference **does NOT increase the reference count** â€” object can be garbage collected.

```python
import weakref

class ExpensiveObject:
    def __init__(self, name):
        self.name = name
    def __repr__(self):
        return f"ExpensiveObject({self.name})"
    def __del__(self):
        print(f"{self.name} destroyed!")

# ---- Normal reference (keeps object alive) ----
obj = ExpensiveObject("strong")
ref = obj        # Strong reference â†’ refcount = 2
del obj          # refcount = 1 â†’ NOT destroyed!
print(ref)       # ExpensiveObject(strong) â€” still alive!
del ref          # refcount = 0 â†’ "strong destroyed!"

# ---- Weak reference (doesn't keep alive) ----
obj = ExpensiveObject("weak")
weak_ref = weakref.ref(obj)    # Weak reference â†’ refcount stays 1

print(weak_ref())     # ExpensiveObject(weak) â€” access via ()
del obj               # refcount = 0 â†’ "weak destroyed!"
print(weak_ref())     # None â€” object is gone!
```

### `WeakValueDictionary` â€” Cache That Auto-Cleans
```python
import weakref

class User:
    def __init__(self, user_id, name):
        self.id = user_id
        self.name = name

# Cache using weak references
cache = weakref.WeakValueDictionary()

def get_user(user_id):
    if user_id in cache:
        print(f"Cache hit for {user_id}")
        return cache[user_id]
    
    print(f"Cache miss for {user_id}")
    user = User(user_id, f"User-{user_id}")
    cache[user_id] = user
    return user

u1 = get_user(1)    # Cache miss
u2 = get_user(1)    # Cache hit!

del u1, u2           # No strong references â†’ automatically removed from cache!
print(dict(cache))   # {} â€” auto-cleaned!
```

---

## 5. Memory Profiling (`memory_profiler`, `tracemalloc`)

### `tracemalloc` (Built-in)
```python
import tracemalloc

# ---- Start tracing ----
tracemalloc.start()

# Your code here
my_list = [i**2 for i in range(100_000)]
my_dict = {i: i**2 for i in range(50_000)}

# ---- Get memory snapshot ----
snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics("lineno")

print("Top 5 memory consumers:")
for stat in top_stats[:5]:
    print(f"  {stat}")

# ---- Compare snapshots (find leaks!) ----
tracemalloc.start()
snapshot1 = tracemalloc.take_snapshot()

# ... do some work ...
data = [list(range(1000)) for _ in range(1000)]

snapshot2 = tracemalloc.take_snapshot()
diff = snapshot2.compare_to(snapshot1, "lineno")

print("Memory changes:")
for stat in diff[:5]:
    print(f"  {stat}")

# ---- Current memory usage ----
current, peak = tracemalloc.get_traced_memory()
print(f"Current: {current / 1024:.1f} KB")
print(f"Peak: {peak / 1024:.1f} KB")

tracemalloc.stop()
```

### `memory_profiler` (Third-Party)
```python
# pip install memory_profiler

from memory_profiler import profile

@profile
def my_function():
    a = [1] * 1_000_000         # ~8MB
    b = [2] * 2_000_000         # ~16MB
    del b                        # Free ~16MB
    c = [3] * 3_000_000         # ~24MB
    return c

my_function()

# Output:
# Line #    Mem usage    Increment   Line Contents
# ============================================
#   5      45.0 MiB     0.0 MiB   @profile
#   6      52.6 MiB     7.6 MiB   a = [1] * 1_000_000
#   7      67.9 MiB    15.3 MiB   b = [2] * 2_000_000
#   8      52.6 MiB   -15.3 MiB   del b
#   9      75.4 MiB    22.9 MiB   c = [3] * 3_000_000
```

---

## 6. `__slots__` for Memory Savings

By default, Python stores instance attributes in a `__dict__` (dictionary). `__slots__` replaces that with a fixed tuple â€” saves memory.

```python
import sys

# ---- Without __slots__ (default) ----
class UserNormal:
    def __init__(self, name, age, email):
        self.name = name
        self.age = age
        self.email = email

# ---- With __slots__ ----
class UserSlots:
    __slots__ = ("name", "age", "email")
    
    def __init__(self, name, age, email):
        self.name = name
        self.age = age
        self.email = email

# Memory comparison
normal = UserNormal("Sid", 25, "sid@example.com")
slotted = UserSlots("Sid", 25, "sid@example.com")

print(sys.getsizeof(normal))                   # 48 bytes
print(sys.getsizeof(normal.__dict__))           # 232 bytes (the dict!)
print(sys.getsizeof(slotted))                   # 56 bytes (NO dict!)

# With 1 million objects:
# Normal:  ~280 bytes Ã— 1M = ~280MB
# Slots:   ~56 bytes Ã— 1M  = ~56MB  (5x less memory!)
```

### `__slots__` Rules
```python
class User:
    __slots__ = ("name", "age")
    
    def __init__(self, name, age):
        self.name = name
        self.age = age

u = User("Sid", 25)

# âŒ Can't add new attributes!
# u.email = "sid@example.com"    â†’ AttributeError!

# âŒ No __dict__
# print(u.__dict__)              â†’ AttributeError!

# âœ… Can still have methods, properties, class variables
class Product:
    __slots__ = ("name", "_price")
    category = "General"    # Class variable (OK!)
    
    def __init__(self, name, price):
        self.name = name
        self._price = price
    
    @property
    def price(self):
        return self._price

# âœ… Slots with inheritance (add parent slots)
class Admin(User):
    __slots__ = ("role",)    # Adds to parent's slots
    # Admin has: name, age, role
```

### When to Use `__slots__`

| Use `__slots__` | Don't Use |
|----------------|-----------|
| Creating millions of objects | Few objects |
| Memory-critical applications | Normal applications |
| Data models / value objects | Classes needing dynamic attributes |
| ORM model fields | Classes using `__dict__` features |

---

## ğŸ”— Quick Reference

```python
import sys, gc, weakref, tracemalloc

# ---- Reference counting ----
sys.getrefcount(obj)         # Check reference count

# ---- Garbage collection ----
gc.collect()                 # Force GC
gc.get_count()               # Objects per generation
gc.get_threshold()           # GC trigger thresholds

# ---- Object size ----
sys.getsizeof(obj)           # Shallow size in bytes

# ---- Weak references ----
ref = weakref.ref(obj)       # Create weak reference
ref()                        # Access (returns None if collected)
cache = weakref.WeakValueDictionary()  # Auto-cleaning cache

# ---- Memory profiling ----
tracemalloc.start()
snapshot = tracemalloc.take_snapshot()
current, peak = tracemalloc.get_traced_memory()
tracemalloc.stop()

# ---- __slots__ (save memory) ----
class MyClass:
    __slots__ = ("attr1", "attr2")   # No __dict__ â†’ 5x less memory
```

---

> ğŸ“ **Next up**: 7.5 Metaprogramming â€” Metaclasses, `type()`, descriptors, `inspect`
